{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skai_clean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20ukgalaHmc1"
      },
      "source": [
        "#**[Task 1a] cleaning**\n",
        "\n",
        "\n",
        "\n",
        "*   Clean the subject - removing the prefixes & alphanumeric stings.\n",
        "*   Clean the body.\n",
        "*   Filter the mails for language.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehuN5pu7aHPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82abb6cc-08b9-4430-d435-0a6a14a2f8c0"
      },
      "source": [
        "#import modules\n",
        "!pip install langdetect\n",
        "import pandas as pd\n",
        "import regex\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from langdetect import detect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\r\u001b[K     |▍                               | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 16.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 286kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 296kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 317kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 327kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 348kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 358kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 378kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 389kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 409kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 419kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 440kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 450kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 471kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 481kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 501kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 512kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 532kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 542kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 563kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 573kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 593kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 604kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 624kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 634kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 655kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 665kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 686kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 696kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 716kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 727kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 747kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 757kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 768kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 778kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 788kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 798kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 808kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 819kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 829kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 839kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 849kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 860kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 870kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 880kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 890kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 901kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 911kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 921kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 931kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 942kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 952kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 962kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 972kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 983kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=7e6b0f899f018a2fe30e511c8a7c9e27433af91075dd01488c5ef749d41d9f0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfOBAN_FaieR",
        "outputId": "c7ea2ab4-b997-4f12-c4d0-d1fdfbf19bae"
      },
      "source": [
        "#load data\n",
        "cleanedDataPath = \"train.csv\" # file path\n",
        "\n",
        "df = pd.read_csv(cleanedDataPath, sep=\";\", encoding=\"utf8\")\n",
        "print(\"Number of overall Incidents: \" + str(df.Id.size))\n",
        "df = df.dropna(subset=['MailTextBody'])\n",
        "df = df.dropna(subset=['MailSubject'])\n",
        "print(\"Number of Incidents with body: \" + str(df.Id.size))\n",
        "print(\"columns: \", list(df.columns.values))\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df = df.sort_values(by='Id', ascending=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of overall Incidents: 2845\n",
            "Number of Incidents with body: 2841\n",
            "columns:  ['Unnamed: 0', 'Id', 'Impact', 'Urgency', 'IncidentType', 'ServiceProcessed', 'MailSubject', 'MailTextBody', 'ManualGroups']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afnb50xZ2b3B",
        "outputId": "de607e95-fdaf-4275-de23-39bd10d0b9ba"
      },
      "source": [
        "# clean subject\n",
        "def cleanSub(sub):\n",
        "  try:\n",
        "    wordList = word_tokenize(sub)\n",
        "    if len(wordList) <= 1:\n",
        "      return sub\n",
        "    if wordList[1] == ':':\n",
        "      wordList.pop(0)\n",
        "      wordList.pop(0)\n",
        "    if wordList[-2] == ':':\n",
        "      wordList.pop(-1)\n",
        "      wordList.pop(-1)\n",
        "      wordList.pop(-1)\n",
        "    if any(ch == ':' for ch in str(wordList[0])):\n",
        "      wordList.pop(0)\n",
        "    if any(ch == ':' for ch in str(wordList[-1])):\n",
        "      wordList.pop(-1)\n",
        "    return ' '.join(word for word in wordList)\n",
        "  except:\n",
        "    return sub\n",
        "\n",
        "# Clean text\n",
        "def beautify_text(text):\n",
        "    text = text.replace('\\\\r',' ')\n",
        "    text = text.replace('\\\\n','')\n",
        "    text = text.replace('\\r',' ')\n",
        "    text = text.replace('\\n','')\n",
        "    text = text.replace('  ',' ')\n",
        "    text = text.lower()\n",
        "    text = text.replace('&nbsp;','')\n",
        "    return text.strip()\n",
        "\n",
        "# detect language\n",
        "def detectLanguage(x):\n",
        "    try:\n",
        "        return detect(x)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "df['MailSubject'] = df['MailSubject'].apply(cleanSub)\n",
        "df['MailTextBody'] = df['MailTextBody'].apply(beautify_text)\n",
        "df['MailLanguage'] = df['MailTextBody'].apply(detectLanguage)\n",
        "languageGroupedDf = df.groupby('MailLanguage')\n",
        "pd.set_option('display.max_rows', None)\n",
        "mailsByLanguage = languageGroupedDf.size().sort_values(ascending=False)\n",
        "print(mailsByLanguage.nlargest(n=10))\n",
        "\n",
        "df_de = df[(df['MailLanguage'] == 'de')]\n",
        "\n",
        "pd.set_option('display.max_colwidth',200)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df_de.head()\n",
        "\n",
        "# save cleaned file \n",
        "df_de.to_csv('train_clean.csv', index=False, sep=\";\")   # filtered data file to save"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "MailLanguage\n",
            "de    2659\n",
            "en     133\n",
            "fr      34\n",
            "it       4\n",
            "so       2\n",
            "nl       2\n",
            "da       2\n",
            "sv       1\n",
            "no       1\n",
            "hu       1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "_n8J9qj_Gtzo",
        "outputId": "96b6b411-9fc0-4a46-c75b-3eabfcdecdce"
      },
      "source": [
        "df_de.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id</th>\n",
              "      <th>Impact</th>\n",
              "      <th>Urgency</th>\n",
              "      <th>IncidentType</th>\n",
              "      <th>ServiceProcessed</th>\n",
              "      <th>MailSubject</th>\n",
              "      <th>MailTextBody</th>\n",
              "      <th>ManualGroups</th>\n",
              "      <th>MailLanguage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3554</td>\n",
              "      <td>INC000010587669</td>\n",
              "      <td>4-Minor/Localized</td>\n",
              "      <td>2-High</td>\n",
              "      <td>Failure</td>\n",
              "      <td>EDA_S_BA_2FA</td>\n",
              "      <td>smart card blockiert</td>\n",
              "      <td>lieber helpdesk sie haben mir den computer freigeschaltet, weil meine smartcard blockiert ist. ich bin nun in ausserholligen und möchte die smardcard gern deblockieren. was muss ich tun? bin jetzt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3553</td>\n",
              "      <td>INC000010585556</td>\n",
              "      <td>4-Minor/Localized</td>\n",
              "      <td>4-Low</td>\n",
              "      <td>Service Request</td>\n",
              "      <td>EDA_S_Order Management</td>\n",
              "      <td>Webcam</td>\n",
              "      <td>liebe kolleginnen und kollegen ich möchte für susanne caseri eine webcam für videokoferenzen bestellen, die man am bildschirm befestigen kann. mit bestem dank und vielen grüsse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3552</td>\n",
              "      <td>INC000010585519</td>\n",
              "      <td>4-Minor/Localized</td>\n",
              "      <td>4-Low</td>\n",
              "      <td>Failure</td>\n",
              "      <td>EDA_S_Peripheriegeräte</td>\n",
              "      <td>IT Support heute Nachmittag</td>\n",
              "      <td>liebe kolleginnen und kollegen es handelt sich um eine sitzung der deza-direktion heute um 16.30 uhr im sitzungszimmer 0 1 2 3 . darf ich sie gem. untenstehendem mail bitten, dass jemand vor ort s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3549</td>\n",
              "      <td>INC000010582950</td>\n",
              "      <td>4-Minor/Localized</td>\n",
              "      <td>4-Low</td>\n",
              "      <td>Service Request</td>\n",
              "      <td>EDA_S_Benutzerunterstützung</td>\n",
              "      <td>Botschaft Warschau - Administratoren-Zugang für MS Teams</td>\n",
              "      <td>sehr geehrte damen und herren, die botschaft in warschau plant am 18. november ein webinar zu organisieren. in diesem zusammenhang wurde ich intern gebeten, für mich einen administratoren-zugang f...</td>\n",
              "      <td>Benutzeranleitungen_Telefonie</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3548</td>\n",
              "      <td>INC000010582919</td>\n",
              "      <td>4-Minor/Localized</td>\n",
              "      <td>4-Low</td>\n",
              "      <td>Service Request</td>\n",
              "      <td>EDA_S_Order Management</td>\n",
              "      <td>Commande d'un écran</td>\n",
              "      <td>liebe kolleginnen und kollegen ich möchte für frédéric noirjean einen zweiten bildschirm bestellen. leider klappt die bestellung über egate nicht. ich kann keinen bildschirm auswählen. besten dank...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0               Id             Impact Urgency     IncidentType  \\\n",
              "0        3554  INC000010587669  4-Minor/Localized  2-High          Failure   \n",
              "1        3553  INC000010585556  4-Minor/Localized   4-Low  Service Request   \n",
              "2        3552  INC000010585519  4-Minor/Localized   4-Low          Failure   \n",
              "3        3549  INC000010582950  4-Minor/Localized   4-Low  Service Request   \n",
              "4        3548  INC000010582919  4-Minor/Localized   4-Low  Service Request   \n",
              "\n",
              "              ServiceProcessed  \\\n",
              "0                 EDA_S_BA_2FA   \n",
              "1       EDA_S_Order Management   \n",
              "2       EDA_S_Peripheriegeräte   \n",
              "3  EDA_S_Benutzerunterstützung   \n",
              "4       EDA_S_Order Management   \n",
              "\n",
              "                                                MailSubject  \\\n",
              "0                                      smart card blockiert   \n",
              "1                                                    Webcam   \n",
              "2                               IT Support heute Nachmittag   \n",
              "3  Botschaft Warschau - Administratoren-Zugang für MS Teams   \n",
              "4                                       Commande d'un écran   \n",
              "\n",
              "                                                                                                                                                                                              MailTextBody  \\\n",
              "0  lieber helpdesk sie haben mir den computer freigeschaltet, weil meine smartcard blockiert ist. ich bin nun in ausserholligen und möchte die smardcard gern deblockieren. was muss ich tun? bin jetzt...   \n",
              "1                         liebe kolleginnen und kollegen ich möchte für susanne caseri eine webcam für videokoferenzen bestellen, die man am bildschirm befestigen kann. mit bestem dank und vielen grüsse   \n",
              "2  liebe kolleginnen und kollegen es handelt sich um eine sitzung der deza-direktion heute um 16.30 uhr im sitzungszimmer 0 1 2 3 . darf ich sie gem. untenstehendem mail bitten, dass jemand vor ort s...   \n",
              "3  sehr geehrte damen und herren, die botschaft in warschau plant am 18. november ein webinar zu organisieren. in diesem zusammenhang wurde ich intern gebeten, für mich einen administratoren-zugang f...   \n",
              "4  liebe kolleginnen und kollegen ich möchte für frédéric noirjean einen zweiten bildschirm bestellen. leider klappt die bestellung über egate nicht. ich kann keinen bildschirm auswählen. besten dank...   \n",
              "\n",
              "                    ManualGroups MailLanguage  \n",
              "0                            NaN           de  \n",
              "1                            NaN           de  \n",
              "2                            NaN           de  \n",
              "3  Benutzeranleitungen_Telefonie           de  \n",
              "4                            NaN           de  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRbcVLSKJbBr"
      },
      "source": [
        "#**[Task 1b] Embedding (Doc2Vec)**\n",
        "\n",
        "\n",
        "*   Get the embedding using Doc2Vec (tfhub)\n",
        "*   Train ML classfier for predicting labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7N3yGLTcuk"
      },
      "source": [
        "# import\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex\n",
        "import re\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_6IRAP7LI6C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReDa4VvVTdvN"
      },
      "source": [
        "cleanedDataPath = \"train_clean.csv\"\n",
        "\n",
        "df = pd.read_csv(cleanedDataPath, sep=\";\", encoding=\"utf8\")\n",
        "print(\"Number of Incidents loaded: \" + str(df.Id.size))\n",
        "\n",
        "# df.head()\n",
        "embedding_text = []\n",
        "embedding_sub = []\n",
        "\n",
        "for i, f in df.iterrows():\n",
        "    if i == 0:\n",
        "      embedding_text = embed([f.MailTextBody]).numpy()\n",
        "      embedding_sub = embed([f.MailSubject]).numpy()\n",
        "    else:\n",
        "      embedding_text = np.concatenate((embedding_text, embed([f.MailTextBody]).numpy()), axis=0)\n",
        "      embedding_sub = np.concatenate((embedding_sub, embed([f.MailSubject]).numpy()), axis=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qRCZqLWMIFa"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTUZZOJ2XTUy",
        "outputId": "5c075178-631e-4a89-8993-fb14f2d78a5e"
      },
      "source": [
        "# import\n",
        "from sklearn import svm, preprocessing, feature_selection\n",
        "from imblearn import under_sampling, over_sampling, combine\n",
        "np.random.seed(0)\n",
        "\n",
        "#lable\n",
        "class_list = np.unique(df['ServiceProcessed'].dropna()).tolist()\n",
        "y = df.apply(lambda x:  class_list.index(x['ServiceProcessed']),axis=1)\n",
        "X = np.concatenate((embedding_sub, embedding_text), axis=1)\n",
        "\n",
        "# basic feature selction\n",
        "f_test, _ = feature_selection.f_classif(X, y)\n",
        "f_test[np.isnan(f_test)] = 0\n",
        "f_test /= np.max(f_test)\n",
        "indexes = np.where(f_test > 0.2)\n",
        "X = X[:, indexes]\n",
        "X = X[:, 0, :]\n",
        "\n",
        "# test train data gen\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# normalization\n",
        "X_scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = X_scaler.transform(X_train)\n",
        "X_test = X_scaler.transform(X_test)\n",
        "\n",
        "# # supersampling\n",
        "# cc = over_sampling.RandomOverSampler(random_state=0)\n",
        "# # hybrid sampling - doen't work too few data points\n",
        "# cc = combine.SMOTEENN(random_state=0)\n",
        "# X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
        "\n",
        "# clf = RandomForestClassifier()\n",
        "# clf = xgb.XGBClassifier(),\n",
        "# clf = RandomForestClassifier(),\n",
        "clf = SVC(gamma='auto', decision_function_shape='ovo', class_weight='balanced')\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45077501668169545"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD70R1YwNQlv"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTd-xAZTNP9D"
      },
      "source": [
        "# training\n",
        "cleanedDataPath = \"train_clean.csv\"\n",
        "df = pd.read_csv(cleanedDataPath, sep=\";\", encoding=\"utf8\")\n",
        "print(\"Number of Incidents loaded: \" + str(df.Id.size))\n",
        "\n",
        "embedding_text = []\n",
        "embedding_sub = []\n",
        "for i, f in df.iterrows():\n",
        "    if i == 0:\n",
        "      embedding_text = embed([f.MailTextBody]).numpy()\n",
        "      embedding_sub = embed([f.MailSubject]).numpy()\n",
        "    else:\n",
        "      embedding_text = np.concatenate((embedding_text, embed([f.MailTextBody]).numpy()), axis=0)\n",
        "      embedding_sub = np.concatenate((embedding_sub, embed([f.MailSubject]).numpy()), axis=0)\n",
        "\n",
        "x_train = np.concatenate((embedding_sub, embedding_text), axis=1)\n",
        "class_list = np.unique(df['ServiceProcessed'].dropna()).tolist()\n",
        "y_train = df.apply(lambda x:  class_list.index(x['ServiceProcessed']),axis=1)\n",
        "\n",
        "x_scaler = preprocessing.StandardScaler().fit(x_train)\n",
        "x_train = x_scaler.transform(x_train)\n",
        "\n",
        "cc = over_sampling.RandomOverSampler(random_state=0)\n",
        "x_resampled, y_resampled = cc.fit_resample(x_train, y_train)\n",
        "\n",
        "clf = SVC(gamma='auto', decision_function_shape='ovo', class_weight='balanced')\n",
        "clf.fit(x_resampled, y_resampled)\n",
        "\n",
        "# prediction\n",
        "cleanedDataPath = \"test_reduced.csv\"\n",
        "df_test = pd.read_csv(cleanedDataPath, sep=\";\", encoding=\"utf8\")\n",
        "print(\"Number of Incidents loaded: \" + str(df_test.Id.size))\n",
        "\n",
        "embedding_text = []\n",
        "embedding_sub = []\n",
        "\n",
        "for i, f in df_test.iterrows():\n",
        "    if i == 0:\n",
        "      embedding_text = embed([f.MailTextBody]).numpy()\n",
        "      embedding_sub = embed([f.MailSubject]).numpy()\n",
        "    else:\n",
        "      embedding_text = np.concatenate((embedding_text, embed([f.MailTextBody]).numpy()), axis=0)\n",
        "      embedding_sub = np.concatenate((embedding_sub, embed([f.MailSubject]).numpy()), axis=0)\n",
        "\n",
        "x_test = np.concatenate((embedding_sub, embedding_text), axis=1)\n",
        "x_test = x_scaler.transform(x_test)\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "df_test['Predicted'] = y_pred\n",
        "df_test['Predicted'] = df_test.apply(lambda x:  class_list[x['Predicted']],axis=1)\n",
        "df_test = df_test[['Id', 'Predicted']]\n",
        "df_test.to_csv('submission.csv', index=False)   # save to file"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}